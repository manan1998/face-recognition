{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### OpenCV-Python is a library of Python bindings designed to solve computer vision problems.\n",
    "\n",
    "OpenCV supports a wide variety of programming languages such as C++, Python, Java, etc., and is available on different platforms including Windows, Linux, OS X, Android, and iOS.\n",
    "\n",
    "OpenCV-Python makes use of Numpy, which is a highly optimized library for numerical operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.4.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import pygame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### open webcam and capture a frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webcam = cv2.VideoCapture(1)\n",
    "ret ,frame = webcam.read()\n",
    "print(ret)\n",
    "webcam.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### webcam.read(): returns a frame and boolean value(True/False)..if frame is read correctly, it will be True. \n",
    "\n",
    "#### webcam.release() :to close webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"opencv_2\", frame)\n",
    " \n",
    "# Press any key to close external window\n",
    "cv2.waitKey(0)   \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cv.waitKey() is a keyboard binding function. Its argument is the time in milliseconds. The function waits for specified milliseconds for any keyboard event. If you press any key in that time, the program continues. If 0 is passed, it waits indefinitely for a key stroke\n",
    "\n",
    "\n",
    "#### cv.destroyAllWindows() simply destroys all the windows we created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To create external window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow('open_cv', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('open_cv',frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(frame)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### matplotlib support RGB and opencv support BGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_RGB = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(frame_RGB)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and Write Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('picture_RGB.jpg',frame_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picture = cv2.imread('picture_RGB.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(picture)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open connection to camera\n",
    "webcam = cv2.VideoCapture(1)\n",
    "\n",
    "#External Window or in Notebook\n",
    "cv2.namedWindow(\"opencv_1\", cv2.WINDOW_AUTOSIZE)\n",
    " \n",
    "while True:\n",
    "      \n",
    "    ret, frame = webcam.read()\n",
    "    cv2.imshow(\"opencv_1\", frame) \n",
    "     \n",
    "    # Press q for close window\n",
    "    #here 10 is a milliseconds\n",
    "    if cv2.waitKey(10)== ord('q'):\n",
    "        break\n",
    "webcam.release()        \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Detection using Haar Cascades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of available pretraied models in OpenCV:\n",
    "\n",
    "<div style=\"float: left; width: 50%\">\n",
    "<ul>\n",
    "    <li> haarcascade_eye_tree_eyeglasses  \n",
    "    <li> haarcascade_mcs_leftear\n",
    "    <li> haarcascade_eye                  \n",
    "    <li> haarcascade_mcs_lefteye\n",
    "    <li> haarcascade_frontalface_alt2   \n",
    "    <li> haarcascade_mcs_mouth\n",
    "    <li> haarcascade_frontalface_alt_tree\n",
    "    <li> haarcascade_mcs_nose\n",
    "    <li> <font style=\"color: #be2830\">haarcascade_frontalface_alt</font>       \n",
    "    <li> haarcascade_mcs_rightear\n",
    "    <li> haarcascade_frontalface_default\n",
    "</ul>\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%\">\n",
    "<ul>\n",
    "    <li> haarcascade_mcs_righteye\n",
    "    <li> haarcascade_fullbody            \n",
    "    <li> haarcascade_mcs_upperbody\n",
    "    <li> haarcascade_lefteye_2splits    \n",
    "    <li> haarcascade_profileface\n",
    "    <li> haarcascade_lowerbody            \n",
    "    <li> haarcascade_righteye_2splits\n",
    "    <li> haarcascade_mcs_eyepair_big     \n",
    "    <li> haarcascade_smile\n",
    "    <li> haarcascade_mcs_eyepair_small\n",
    "    <li> haarcascade_upperbody\n",
    "</ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting Faces with OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### detector = cv2.CascadeClassifier( xml_file_path)\n",
    "\n",
    "### face_coord = detector.detectMultiScale(image, scale_factor, min_neighbors, min_size, max_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### image : gray scale image where face are detected.\n",
    "\n",
    "\n",
    "#### scale_factor:Parameter specifying how much the image size is reduced at each image scale.\n",
    "\n",
    "\n",
    "#### minNeighbors – Parameter specifying how many neighbors each candidate rectangle should have to retain it.\n",
    "\n",
    "\n",
    "#### minSize – Minimum possible object size. Objects smaller than that are ignored.\n",
    "\n",
    "\n",
    "#### maxSize – Maximum possible object size. Objects larger than that are ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picture.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faceDetect=cv2.CascadeClassifier('xml/frontal_face.xml')\n",
    "cam = cv2.VideoCapture(1)\n",
    "\n",
    "cv2.namedWindow(\"Face\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "while True:\n",
    "    ret,img = cam.read()\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceDetect.detectMultiScale(gray,scaleFactor=1.2,minNeighbors=5)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    cv2.imshow(\"Face\",img)\n",
    "    if (cv2.waitKey(10)== ord('q')):\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\" style='color: #be2830'>Build Our Dataset</h2>\n",
    "<h4 align=\"center\">\n",
    "Detect $\\rightarrow$ Cut $\\rightarrow$ Normalize $\\rightarrow$ Resize $\\rightarrow$ Save</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### detect face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(frame):\n",
    "    if frame.ndim!=2:\n",
    "        frame = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    detector = cv2.CascadeClassifier(\"xml/frontal_face.xml\")\n",
    "\n",
    "    faces = detector.detectMultiScale(frame,1.2,5)\n",
    "    \n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray_scale(image):\n",
    "    if image.ndim!=2:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cut face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_faces(image, faces_coord):\n",
    "    faces = []\n",
    "      \n",
    "    for (x, y, w, h) in faces_coord:\n",
    "        \n",
    "        faces.append(image[y: y + h, x : x + w ])\n",
    "         \n",
    "    return faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize faces by increasing pixel intensity(brightness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_intensity(images):\n",
    "    images_norm = []\n",
    "    for image in images:\n",
    "        is_color = len(image.shape) == 3 \n",
    "        if is_color:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        images_norm.append(cv2.equalizeHist(image))   #passes grayscale image into equalizeHist as parameter\n",
    "    return images_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize\n",
    "\n",
    "#### cv.INTER_AREA for shrinking & cv.INTER_CUBIC for zooming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(images,size=(47,62)):\n",
    "    image_resize = []\n",
    "    \n",
    "    for image in images:\n",
    "        if image.shape < size:\n",
    "            img_size = cv2.resize(image,size,interpolation=cv2.INTER_CUBIC)   #interpolation is used for zooming in hereby passing inter_cubic\n",
    "        else:\n",
    "            img_size = cv2.resize(image,size,interpolation=cv2.INTER_AREA)#interpolation here is used for to manipulate if size of face is greater than given size i.e.(47,62)\n",
    "        image_resize.append(img_size)\n",
    "        \n",
    "    return image_resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_faces(frame, faces_coord):\n",
    "    gray_frame = gray_scale(frame)\n",
    "    faces = cut_faces(gray_frame, faces_coord)\n",
    "    faces = normalize_intensity(faces)\n",
    "    \n",
    "    faces = resize(faces)\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_show(image,title=\"\"):\n",
    "    if len(image.shape) == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    plt.axis(\"off\")   #to remove the values of x & y from the axis\n",
    "    plt.title(title)\n",
    "    plt.imshow(image,cmap=\"Greys_r\")  #for image in grayscale color mapping\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rectangle(image, coords):\n",
    "    for (x, y, w, h) in coords:\n",
    "        #w_rm = int(0.2 * w / 2) \n",
    "        cv2.rectangle(image, (x , y), (x + w , y + h), (0,0,255),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "cam = cv2.VideoCapture(1)\n",
    "#cv2.namedWindow(\"Face\", cv2.WINDOW_AUTOSIZE)\n",
    "folder = \"people/\"+input('Person:').lower()\n",
    "\n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder)   #to create the folder of name given\n",
    "    \n",
    "    flag_start_capturing = False\n",
    "    sample=1\n",
    "    #cam = cv2.VideoCapture(0)\n",
    "    cv2.namedWindow(\"Face\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "    while True:\n",
    "        ret,frame = cam.read()\n",
    "        \n",
    "        \n",
    "        \n",
    "        faces_coord = detect_face(frame)\n",
    "\n",
    "        if len(faces_coord):\n",
    "            faces = normalize_faces(frame,faces_coord)   #cuts the face and normalise its intensity\n",
    "            #faces = normalize_intensity(faces)\n",
    "            cv2.imwrite(folder + '/' + str(sample)+'.jpg',faces[0])  #save face as file\n",
    "            plot_show(faces[0],\"Image saved:\"+str(sample))  #to display the face\n",
    "            clear_output(wait=True)   #removes the previous picture printed\n",
    "            if flag_start_capturing == True:\n",
    "                sample += 1\n",
    "            \n",
    "        draw_rectangle(frame,faces_coord)\n",
    "        cv2.imshow('Face',frame)\n",
    "        keypress=cv2.waitKey(1)\n",
    "        \n",
    "        if keypress == ord('c'):   #after pressing c the pictures start capturing after the first picture taken\n",
    "            \n",
    "            if flag_start_capturing == False:\n",
    "                flag_start_capturing = True\n",
    "            \n",
    "        \n",
    "        if sample >500:\n",
    "            break\n",
    "\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print (\"This name already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset for unknown people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5760\n"
     ]
    }
   ],
   "source": [
    "### datasets for other class\n",
    "\n",
    "basepath = 'C:\\\\Users\\\\manan\\\\scikit_learn_data\\\\lfw_home\\\\lfw_funneled'\n",
    "#/home/manan/scikit_learn_data/lfw_home\n",
    "images = os.listdir(basepath) #all folder names are stored in images \n",
    "print (len(images))\n",
    "data = images[:210]  #picked 200 folders from starting and then processed for unknown dataset.\n",
    "for i,folder in enumerate(data,start=1): #enumerate is used to put folder names in data and start indexing from 1.\n",
    "    \n",
    "    files=os.listdir(basepath+'/'+folder)  #all the images' name are stored in files\n",
    "    for k,img in enumerate(files,start=1):\n",
    "        if img.endswith('.jpg'):   #to check that it is an image\n",
    "            #print img\n",
    "            frame=cv2.imread(basepath+'/'+folder+'/'+img,0) #reads the image also 0 indicates it to be read as grayscale image.\n",
    "        #print frame\n",
    "            \n",
    "            faces_coord = detect_face(frame)\n",
    "            if len(faces_coord):\n",
    "                faces = cut_faces(frame, faces_coord)\n",
    "                #print faces\n",
    "                faces = normalize_intensity(faces)\n",
    "                faces = resize(faces)\n",
    "                cv2.imwrite('people/unknown/' + str(i)+'.jpg',faces[0])\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### collect dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_dataset():  #read all the faces and store them in the form of an array.\n",
    "    images = []\n",
    "    labels = []\n",
    "    labels_dic = {}\n",
    "    #people = [person for person in os.listdir(\"Male_female/\")]\n",
    "    people = [person for person in os.listdir(\"people/\")]\n",
    "    #people = [person for person in os.listdir(\"people/\")]\n",
    "    for i, person in enumerate(people):\n",
    "        labels_dic[i] = person\n",
    "        for image in os.listdir(\"people/\" + person):\n",
    "            if image.endswith('.jpg'):\n",
    "                images.append(cv2.imread(\"people/\" + person + '/' + image, 0))\n",
    "                labels.append(i)\n",
    "    return (images, np.array(labels), labels_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels, labels_dic = collect_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2204\n",
      "{0: 'mann', 1: 'mkj', 2: 'mnn', 3: 'popo', 4: 'ppp', 5: 'unknown'}\n"
     ]
    }
   ],
   "source": [
    "print (len(images))\n",
    "print (labels_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 5, 5, 5])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.asarray(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2204, 62, 47)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=X_train.reshape(len(X_train),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2204, 2914)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(train.astype(np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca1 = PCA(n_components=.97)\n",
    "new_train=pca1.fit_transform(X_train_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca1.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV,KFold  #gridsearchcv is used to pass multiple values of C and kFold is used to find number of times data has been executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf=KFold(n_splits=5,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C':[.0001,.001,.01,.1,1,10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_svc = GridSearchCV(SVC(kernel='linear',probability=True),param_grid=param_grid,cv=kf,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_svc.fit(new_train,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9986388384754991"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_svc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.01}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_svc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=gs_svc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "filename = 'svc_linear_face.pkl'\n",
    "f=open(filename, 'wb')\n",
    "pickle.dump(clf,f)\n",
    " \n",
    "\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'svc_linear_face.pkl'\n",
    "svc1 = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.5         0.79724271  2.21246806  4.25447934  3.23580989]]\n",
      "[[0.00417759 0.00283155 0.01590041 0.93762568 0.03946477]]\n",
      "[3] 3\n",
      "Popo\n"
     ]
    }
   ],
   "source": [
    "cam = cv2.VideoCapture(1)\n",
    "font=cv2.FONT_HERSHEY_PLAIN\n",
    "cv2.namedWindow(\"opencv_face\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret,frame = cam.read()\n",
    "    \n",
    "    \n",
    "    faces_coord = detect_face(frame) # detect more than one face\n",
    "    if len(faces_coord):\n",
    "        faces = normalize_faces(frame, faces_coord)\n",
    "        #faces = normalize_intensity(faces)\n",
    "        for i, face in enumerate(faces): # for each detected face\n",
    "            \n",
    "            \n",
    "            #cv2.imwrite('trainingData/female/picture_BGR5.jpg',face)\n",
    "            t=face.reshape(1,-1)\n",
    "            t=sc.transform(t.astype(np.float64))\n",
    "            test = pca1.transform(t)    \n",
    "            #print test\n",
    "            #transform = test.reshape(1,-1)\n",
    "            #print transform\n",
    "            prob=svc1.predict_proba(test)\n",
    "            confidence = svc1.decision_function(test)\n",
    "            print (confidence)\n",
    "            print (prob)\n",
    "           \n",
    "            \n",
    "            \n",
    "            pred = svc1.predict(test)\n",
    "            print (pred,pred[0])\n",
    "           \n",
    "            name=labels_dic[pred[0]].capitalize()\n",
    "            print (name)\n",
    "            \n",
    "            #pred = labels_dic[pred[0]].capitalize()\n",
    "            #threshold = .50\n",
    "            if name==\"Unknown\":\n",
    "                pygame.init()\n",
    "                beep=pygame.mixer.Sound('beep-01a.wav')\n",
    "                beep.play()\n",
    "            \n",
    "                \n",
    "            cv2.putText(frame,name,(faces_coord[i][0], faces_coord[i][1] - 10),\n",
    "                       cv2.FONT_HERSHEY_PLAIN, 2, (66, 53, 243), 2)\n",
    "            \n",
    "                \n",
    "           \n",
    "           # if prob[0][1]>.85:\n",
    "                \n",
    "            #    cv2.putText(frame, 'vineet',(faces_coord[i][0], faces_coord[i][1] - 10),\n",
    "             #               cv2.FONT_HERSHEY_PLAIN, 2, (66, 53, 243), 2)\n",
    "            \n",
    "                \n",
    "            #else:\n",
    "             #   cv2.putText(frame,'unknown',(faces_coord[i][0], faces_coord[i][1] - 10),\n",
    "              #              cv2.FONT_HERSHEY_PLAIN, 3, (66, 53, 243), 2)\n",
    "                \n",
    "                \n",
    "           \n",
    "        clear_output(wait = True)\n",
    "        draw_rectangle(frame, faces_coord) # rectangle around face\n",
    "        \n",
    "    cv2.putText(frame, \"ESC to exit\", (5, frame.shape[0] - 5),cv2.FONT_HERSHEY_PLAIN, 1.3, (66, 53, 243), 2,\n",
    "                cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imshow(\"opencv_face\", frame) # live feed in external\n",
    "    if cv2.waitKey(5) == 27:\n",
    "        break\n",
    "        \n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
